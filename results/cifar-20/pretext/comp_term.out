XAI-SCAN> python simclr.py --config_env configs/env.yml --config_exp configs/pretext/simclr_cifar20.yml
{'setup': 'simclr', 'backbone': 'resnet18', 'model_kwargs': {'head': 'mlp', 'features_dim': 128}, 'train_db_name': 'cifar-20', 'val_db_name': 'cifar-20', 'num_classes': 20, 'criterion': 'simclr', 'criterion_kwargs': {'temperature': 0.1}, 'epochs': 500, 'optimizer': 'sgd', 'optimizer_kwargs': {'nesterov': False, 'weight_decay': 0.0001, 'momentum': 0.9, 'lr': 0.4}, 'scheduler': 'cosine', 'scheduler_kwargs': {'lr_decay_rate': 0.1}, 'batch_size': 512, 'num_workers': 8, 'augmentation_strategy': 'simclr', 'augmentation_kwargs': {'random_resized_crop': {'size': 32, 'scale': [0.2, 1.0]}, 'color_jitter_random_apply': {'p': 0.8}, 'color_jitter': {'brightness': 0.4, 'contrast': 0.4, 'saturation': 0.4, 'hue': 0.1}, 'random_grayscale': {'p': 0.2}, 'normalize': {'mean': [0.5071, 0.4867, 0.4408], 'std': [0.2675, 0.2565, 0.2761]}}, 'transformation_kwargs': {'crop_size': 32, 'normalize': {'mean': [0.5071, 0.4867, 0.4408], 'std': [0.2675, 0.2565, 0.2761]}}, 'pretext_dir': 'C:\\Users\\nilst\\Documents\\Workspace\\1. Semester\\AdvTop_ML\\Project\\XAI-SCAN\\results\\cifar-20\\pretext', 'pretext_checkpoint': 'C:\\Users\\nilst\\Documents\\Workspace\\1. Semester\\AdvTop_ML\\Project\\XAI-SCAN\\results\\cifar-20\\pretext\\checkpoint.pth.tar', 'pretext_model': 'C:\\Users\\nilst\\Documents\\Workspace\\1. Semester\\AdvTop_ML\\Project\\XAI-SCAN\\results\\cifar-20\\pretext\\model.pth.tar', 'topk_neighbors_train_path': 'C:\\Users\\nilst\\Documents\\Workspace\\1. Semester\\AdvTop_ML\\Project\\XAI-SCAN\\results\\cifar-20\\pretext\\topk-train-neighbors.npy', 'topk_neighbors_val_path': 'C:\\Users\\nilst\\Documents\\Workspace\\1. Semester\\AdvTop_ML\\Project\\XAI-SCAN\\results\\cifar-20\\pretext\\topk-val-neighbors.npy'}
Retrieve model
Model is ContrastiveModel
Model parameters: 11.50M
ContrastiveModel(
  (backbone): ResNet(
    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (layer1): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (1): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
    )
    (layer2): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential(
          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
    )
    (layer3): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
    )
    (layer4): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
    )
    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  )
  (contrastive_head): Sequential(
    (0): Linear(in_features=512, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=128, bias=True)
  )
)
Set CuDNN benchmark
Retrieve dataset
Train transforms: Compose(
    RandomResizedCrop(size=(32, 32), scale=(0.2, 1.0), ratio=(0.75, 1.3333), interpolation=bilinear, antialias=warn)
    RandomHorizontalFlip(p=0.5)
    RandomApply(
    p=0.8
    ColorJitter(brightness=(0.6, 1.4), contrast=(0.6, 1.4), saturation=(0.6, 1.4), hue=(-0.1, 0.1))
)
    RandomGrayscale(p=0.2)
    ToTensor()
    Normalize(mean=[0.5071, 0.4867, 0.4408], std=[0.2675, 0.2565, 0.2761])
)
Validation transforms: Compose(
    CenterCrop(size=(32, 32))
    ToTensor()
    Normalize(mean=[0.5071, 0.4867, 0.4408], std=[0.2675, 0.2565, 0.2761])
)
Files already downloaded and verified
Files already downloaded and verified
Dataset contains 50000/10000 train/val samples
Build MemoryBank
Files already downloaded and verified
Retrieve criterion
Criterion is SimCLRLoss
Retrieve optimizer
SGD (
Parameter Group 0
    dampening: 0
    differentiable: False
    foreach: None
    lr: 0.4
    maximize: False
    momentum: 0.9
    nesterov: False
    weight_decay: 0.0001
)
No checkpoint file at C:\Users\nilst\Documents\Workspace\1. Semester\AdvTop_ML\Project\XAI-SCAN\results\cifar-20\pretext\checkpoint.pth.tar
Starting main loop
Epoch 0/500
---------------
Adjusted learning rate to 0.40000
Train ...
Epoch: [0][ 0/97]       Loss 6.8348e+00 (6.8348e+00)
Epoch: [0][25/97]       Loss 6.4615e+00 (6.6739e+00)
Epoch: [0][50/97]       Loss 6.3765e+00 (6.5453e+00)
Epoch: [0][75/97]       Loss 6.3267e+00 (6.4674e+00)
Fill memory bank for kNN...
Fill Memory Bank [0/98]
Evaluate ...
Result of kNN evaluation is 15.32
Checkpoint ...
Epoch 1/500
---------------
Adjusted learning rate to 0.40000
Train ...
Epoch: [1][ 0/97]       Loss 6.2047e+00 (6.2047e+00)
Epoch: [1][25/97]       Loss 6.1836e+00 (6.1841e+00)
Epoch: [1][50/97]       Loss 6.0305e+00 (6.1475e+00)
Epoch: [1][75/97]       Loss 5.9731e+00 (6.1047e+00)
Fill memory bank for kNN...
Fill Memory Bank [0/98]
Evaluate ...
Result of kNN evaluation is 18.57
Checkpoint ...
Epoch 2/500
---------------
Adjusted learning rate to 0.39998
Train ...
Epoch: [2][ 0/97]       Loss 5.8523e+00 (5.8523e+00)
Epoch: [2][25/97]       Loss 5.7807e+00 (5.8703e+00)
Epoch: [2][50/97]       Loss 5.5556e+00 (5.7775e+00)
Epoch: [2][75/97]       Loss 5.6467e+00 (5.7025e+00)
Fill memory bank for kNN...
Fill Memory Bank [0/98]
Evaluate ...
Result of kNN evaluation is 18.25
Checkpoint ...
Epoch 3/500
---------------
Adjusted learning rate to 0.39996
Train ...
Epoch: [3][ 0/97]       Loss 5.4489e+00 (5.4489e+00)
Epoch: [3][25/97]       Loss 5.3191e+00 (5.3262e+00)
Epoch: [3][50/97]       Loss 5.1235e+00 (5.2802e+00)
Epoch: [3][75/97]       Loss 5.1959e+00 (5.2337e+00)
Fill memory bank for kNN...
Fill Memory Bank [0/98]
Evaluate ...
Result of kNN evaluation is 21.04
Checkpoint ...

.
..
...

Epoch 498/500
---------------
Adjusted learning rate to 0.00042
Train ...
Epoch: [498][ 0/97]     Loss 4.6133e-01 (4.6133e-01)
Epoch: [498][25/97]     Loss 4.8052e-01 (4.4027e-01)
Epoch: [498][50/97]     Loss 4.2656e-01 (4.3608e-01)
Epoch: [498][75/97]     Loss 4.2522e-01 (4.3309e-01)
Fill memory bank for kNN...
Fill Memory Bank [0/98]
Evaluate ...
Result of kNN evaluation is 73.63
Checkpoint ...
Epoch 499/500
---------------
Adjusted learning rate to 0.00040
Train ...
Epoch: [499][ 0/97]     Loss 4.2562e-01 (4.2562e-01)
Epoch: [499][25/97]     Loss 4.7186e-01 (4.3386e-01)
Epoch: [499][50/97]     Loss 4.9156e-01 (4.3375e-01)
Epoch: [499][75/97]     Loss 4.1266e-01 (4.3454e-01)
Fill memory bank for kNN...
Fill Memory Bank [0/98]
Evaluate ...
Result of kNN evaluation is 73.85
Checkpoint ...
Fill memory bank for mining the nearest neighbors (train) ...
Fill Memory Bank [0/98]
Mine the nearest neighbors (Top-20)
Accuracy of top-20 nearest neighbors on train set is 59.21
Fill memory bank for mining the nearest neighbors (val) ...
Fill Memory Bank [0/20]
Mine the nearest neighbors (Top-5)
Accuracy of top-5 nearest neighbors on val set is 56.68